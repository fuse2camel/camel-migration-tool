# Dockerfile.vllm-amd64
FROM python:3.11-slim

RUN apt-get update && apt-get install -y --no-install-recommends \
      git build-essential curl && \
    rm -rf /var/lib/apt/lists/*

ENV CUDA_VISIBLE_DEVICES="" \
    VLLM_TARGET_DEVICE=cpu \
    PIP_NO_CACHE_DIR=1 \
    VLLM_LOGGING_LEVEL=INFO \
    VLLM_USE_MODELSCOPE=false

# CPU-only PyTorch
RUN pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu \
      torch torchvision torchaudio

# vLLM CPU with proper CPU target
RUN pip install --no-cache-dir "huggingface_hub>=0.23" "transformers>=4.43" \
    && VLLM_TARGET_DEVICE=cpu pip install --no-cache-dir vllm

EXPOSE 8000
ENV MODEL="Qwen/Qwen2.5-1.5B-Instruct"

# Use python module directly with explicit device specification
CMD ["python", "-m", "vllm.entrypoints.openai.api_server", "--device", "cpu", "--host", "0.0.0.0", "--port", "8000"]
